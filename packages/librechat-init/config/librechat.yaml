version: 1.3.1
cache: true

interface:
  customWelcome: '$${LIBRECHAT_CUSTOM_WELCOME}'
  privacyPolicy:
    externalUrl: '$${LIBRECHAT_PRIVACY_POLICY_URL}'
    openNewTab: true
  termsOfService:
    externalUrl: '$${LIBRECHAT_TERMS_OF_SERVICE_URL}'
    openNewTab: true
    modalAcceptance: true
    modalTitle: 'Kleingedrucktes'
    modalContent: |
      # Nutzungsbedingungen

      **Wichtiger Hinweis zu KI-generierten Antworten**
      Alle Antworten dieses KI-Systems sollten stets von Menschen überprüft werden. KI-generierte Inhalte können Fehler enthalten und sollten nicht als alleinige Quelle für wichtige Entscheidungen verwendet werden.

      **Datenverarbeitung und Hosting**
      Wir bemühen uns, so viele Komponenten wie möglich selbst zu hosten. Aktuell nutzen wir noch externe Dienste wie OpenRouter, wodurch Daten derzeit an Server in den USA übertragen werden. Unser Ziel ist es, vollständig auf selbst gehostete oder europäische Dienste umzustellen.
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: true
  fileCitations: true
  fileSearch: true
  search: true

memory:
  disabled: false
  personalize: true
  tokenLimit: 2000
  messageWindowSize: 5
  # Memory categories for journalism and fact-checking workflow
  # Restricts memory storage to these structured categories for better consistency
  validKeys:
    # User preferences and communication style
    - "preferences"
    # Work-related: role, organization, department, responsibilities
    - "work_info"
    # Personal information: name, location, contact preferences
    - "personal_info"
    # Current projects, research topics, ongoing investigations
    - "projects"
    # Fact-checking specific: methods, verification approaches, source preferences
    - "factcheck_info"
    # Research context: background info, historical context, related investigations
    - "research_context"
    # Preferred sources, verification methods, trusted outlets
    - "sources"
    # Output format preferences: article style, citation format, structure
    - "output_format"
    # Important deadlines, publication dates, milestones
    - "deadlines"
    # Expertise areas, specializations, domain knowledge
    - "expertise"
    # Final results, conclusions, verified facts from completed fact-checks
    - "results"
  agent:
    provider: "Scaleway"
    # European Open Source model optimized for Memory tasks with cost-effective function calling
    # mistral-small-3.2-24b-instruct-2506: Cost-effective (3-6x cheaper than 70B models), good function calling
    # Supports 128K context window, improved function calling in v3.2, European-hosted
    model: "mistral-small-3.2-24b-instruct-2506"
    instructions: |
      Store reusable info via validKeys: preferences, work_info, personal_info, projects, factcheck_info, research_context, sources, output_format, deadlines, expertise, results. NEVER: greetings, casual chat, trivial/obvious statements. PRIORITY: Explicit user requests ("Merke dir", "Remember", "Speichere") → always store, even if minor. If only greetings/casual/no info AND no explicit request → END without tools. UPDATE: Check existing memories first. If match exists → UPDATE via `set_memory` (merge old+new). Only create new if no match. NEVER delete+recreate. Delete outdated/corrected promptly. Max 2000 tokens/value.
    model_parameters:
      # Low temperature (0.15) for precise, deterministic function calling decisions
      # Mistral Small 3.2 performs best with temp 0.15 for reliable structured output
      temperature: 0.15
      # top_p: 0.95 provides controlled sampling while maintaining flexibility
      # Optimal for Mistral models when paired with low temperature
      top_p: 0.95

endpoints:
  # Agents configuration
  agents:
    disableBuilder: false
    capabilities:
      - "execute_code"
      - "file_search"
      - "actions"
      - "artifacts"
      - "chain"
      - "context"
      - "ocr"
      - "tools"
      - "web_search"

  custom:
    - name: OpenRouter
      apiKey: "$${OPENROUTER_KEY}"
      baseURL: "$${OPENROUTER_BASE_URL}"
      models:
        # Mix of Open Source and proprietary models - Fallback list if fetch fails or fetch is disabled
        # Sorted by Top Weekly popularity
        default: [
          "anthropic/claude-sonnet-4.5",      # Top proprietary model
          "deepseek/deepseek-v3.2",           # Best Open Source
          "google/gemini-2.5-flash-lite",    # Google's lightweight reasoning model, optimized for speed and cost
          "meta-llama/llama-3.3-70b-instruct", # Meta's latest, very popular
          "openai/gpt-5.2",                   # Latest GPT-5 series
          "xiaomi/mimo-v2-flash",             # Popular open-source model
          "deepseek/deepseek-chat",           # Excellent for coding
          "mistralai/mistral-large-2411",     # European option (French)
          "mistralai/mistral-nemo"            # European option (French, smaller)
        ]
        fetch: true
      titleConvo: true
      summarize: true
      headers:
        HTTP-Referer: "$${OPENROUTER_SITE_URL}"
        X-Title: "$${OPENROUTER_APP_NAME}"

    - name: Scaleway
      apiKey: "$${SCALEWAY_API_KEY}"
      baseURL: "$${SCALEWAY_BASE_URL}"
      iconURL: "https://www.scaleway.com/favicon/website/favicon.svg"
      # BASE_URL construction: If SCALEWAY_PROJECT_ID is set, the initialization script
      # automatically constructs the BASE_URL as https://api.scaleway.ai/{project_id}/v1.
      # Otherwise, the default SCALEWAY_BASE_URL value is used.
      models:
        default: [
          "llama-3.3-70b-instruct",           # Chat - Generally Available
          "qwen3-235b-a22b-instruct-2507",    # Chat - Generally Available
          "mistral-small-3.2-24b-instruct-2506", # Chat, Vision - Generally Available
          "gpt-oss-120b",                      # Chat - Generally Available
          "qwen3-coder-30b-a3b-instruct",     # Chat (Code) - Generally Available
          "pixtral-12b-2409",                 # Chat, Vision - Generally Available
          "holo2-30b-a3b",                    # Chat, Vision - PREVIEW
          "devstral-2-123b-instruct-2512",    # Chat - PREVIEW
          "gemma-3-27b-it",                   # Chat, Vision - PREVIEW
          "voxtral-small-24b-2507",           # Chat, Audio transcription - PREVIEW
          "qwen3-embedding-8b",               # Embeddings - Generally Available
          "bge-multilingual-gemma2"           # Embeddings - Generally Available
        ]
        fetch: true
      titleConvo: true
      summarize: true
      headers:
        HTTP-Referer: "$${SCALEWAY_SITE_URL}"
        X-Title: "$${SCALEWAY_APP_NAME}"

# Model Specs: Define default model for new users
# This prevents "My Agents" from being selected when users have no agents
# Note: Memory function uses a separate model (configured in memory.agent section)
# Chat models don't need Function Calling for Memory - Memory works independently
# Models grouped by privacy/transparency: Europe-hosted & Open Source prioritized
modelSpecs:
  list:
    # ==========================================
    # Empfohlen: Europa & Open Source (Scaleway)
    # ==========================================
    - name: "scaleway-llama-3.3-70b"
      label: "Llama 3.3 70B"
      description: "Sehr gut für allgemeine Gespräche und Aufgaben. Von Meta."
      group: "Empfohlen: Europa & Open Source"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWxvY2staWNvbiBsdWNpZGUtbG9jayI+PHJlY3Qgd2lkdGg9IjE4IiBoZWlnaHQ9IjExIiB4PSIzIiB5PSIxMSIgcng9IjIiIHJ5PSIyIi8+PHBhdGggZD0iTTcgMTFWN2E1IDUgMCAwIDEgMTAgMHY0Ii8+PC9zdmc+"
      order: 1
      default: true
      preset:
        endpoint: "Scaleway"
        endpointType: "custom"
        model: "llama-3.3-70b-instruct"
    
    - name: "scaleway-qwen3-235b"
      label: "Qwen3 235B"
      description: "Sehr großes Modell für komplexe Aufgaben."
      group: "Empfohlen: Europa & Open Source"
      order: 2
      preset:
        endpoint: "Scaleway"
        endpointType: "custom"
        model: "qwen3-235b-a22b-instruct-2507"
    
    - name: "scaleway-qwen3-coder-30b"
      label: "Qwen3 Coder 30B"
      description: "Spezialisiert auf Programmierung und Code-Generierung."
      group: "Empfohlen: Europa & Open Source"
      order: 3
      preset:
        endpoint: "Scaleway"
        endpointType: "custom"
        model: "qwen3-coder-30b-a3b-instruct"
    
    - name: "scaleway-gpt-oss-120b"
      label: "GPT-OSS 120B"
      description: "Großes Modell für komplexe Aufgaben."
      group: "Empfohlen: Europa & Open Source"
      order: 4
      preset:
        endpoint: "Scaleway"
        endpointType: "custom"
        model: "gpt-oss-120b"
    
    - name: "scaleway-mistral-small-3.2"
      label: "Mistral Small 3.2 24B"
      description: "Unterstützt Chat und Bilder."
      group: "Empfohlen: Europa & Open Source"
      order: 5
      preset:
        endpoint: "Scaleway"
        endpointType: "custom"
        model: "mistral-small-3.2-24b-instruct-2506"
    
    - name: "scaleway-pixtral-12b"
      label: "Pixtral 12B"
      description: "Für Bildverständnis und Chat."
      group: "Empfohlen: Europa & Open Source"
      order: 6
      preset:
        endpoint: "Scaleway"
        endpointType: "custom"
        model: "pixtral-12b-2409"
    
    # ==========================================
    # Open Source Modelle
    # ==========================================
    - name: "deepseek-v3.2"
      label: "DeepSeek V3.2"
      description: "Kann sehr lange Gespräche führen und komplexe Aufgaben lösen. Sehr gut im logischen Denken."
      group: "Open Source Modelle"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWJvdC1tZXNzYWdlLXNxdWFyZS1pY29uIGx1Y2lkZS1ib3QtbWVzc2FnZS1zcXVhcmUiPjxwYXRoIGQ9Ik0xMiA2VjJIOCIvPjxwYXRoIGQ9Ik0xNSAxMXYyIi8+PHBhdGggZD0iTTIgMTJoMiIvPjxwYXRoIGQ9Ik0yMCAxMmgyIi8+PHBhdGggZD0iTTIwIDE2YTIgMiAwIDAgMS0yIDJIOC44MjhhMiAyIDAgMCAwLTEuNDE0LjU4NmwtMi4yMDIgMi4yMDJBLjcxLjcxIDAgMCAxIDQgMjAuMjg2VjhhMiAyIDAgMCAxIDItMmgxMmEyIDIgMCAwIDEgMiAyeiIvPjxwYXRoIGQ9Ik05IDExdjIiLz48L3N2Zz4="
      order: 1
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "deepseek/deepseek-v3.2"
    
    - name: "llama-3.3-70b"
      label: "Llama 3.3 70B"
      description: "Sehr beliebt für allgemeine Gespräche und Aufgaben. Von Meta."
      group: "Open Source Modelle"
      order: 2
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "meta-llama/llama-3.3-70b-instruct"
    
    - name: "xiaomi-mimo-v2-flash"
      label: "MiMo-V2-Flash"
      description: "Kann sehr lange Gespräche führen. Besonders gut für Wissensthemen, Wissenschaft und Finanzen. Von Xiaomi."
      group: "Open Source Modelle"
      order: 3
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "xiaomi/mimo-v2-flash"
    
    - name: "deepseek-chat-67b"
      label: "DeepSeek Chat 67B"
      description: "Sehr beliebt, besonders gut für Programmierung und Code-Erstellung."
      group: "Open Source Modelle"
      order: 4
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "deepseek/deepseek-chat"
    
    - name: "llama-3.1-8b"
      label: "Llama 3.1 8B"
      description: "Schnell und effizient. Gute Wahl für schnelle Antworten. Von Meta."
      group: "Open Source Modelle"
      order: 5
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "meta-llama/llama-3.1-8b-instruct"
    
    - name: "qwen2.5-vl-72b"
      label: "Qwen2.5-VL 72B"
      description: "Höchste Qualität für Gespräche und Bildverständnis. Kann Bilder analysieren und gleichzeitig natürlich chatten."
      group: "Open Source Modelle"
      order: 6
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "qwen/qwen2.5-vl-72b-instruct"
    
    - name: "qwen2.5-vl-32b"
      label: "Qwen2.5-VL 32B"
      description: "Gute Balance aus Qualität und Geschwindigkeit."
      group: "Open Source Modelle"
      order: 7
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "qwen/qwen2.5-vl-32b-instruct"
    
    - name: "llama-3.2-vision-90b"
      label: "Llama 3.2 Vision 90B"
      description: "Sehr gute Gesprächsqualität. Kann Bilder beschreiben und analysieren. Von Meta."
      group: "Open Source Modelle"
      order: 8
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "meta-llama/llama-3.2-90b-vision-instruct"
    
    # ==========================================
    # Beliebte Premium-Modelle
    # ==========================================
    - name: "claude-sonnet-4.5"
      label: "Claude Sonnet 4.5"
      description: "Eines der besten Modelle für komplexe Aufgaben und Programmierung. Optimiert für praktische Anwendungen."
      group: "Beliebte Premium-Modelle"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWJvdC1pY29uIGx1Y2lkZS1ib3QiPjxwYXRoIGQ9Ik0xMiA4VjRIOCIvPjxyZWN0IHdpZHRoPSIxNiIgaGVpZ2h0PSIxMiIgeD0iNCIgeT0iOCIgcng9IjIiLz48cGF0aCBkPSJNMiAxNGgyIi8+PHBhdGggZD0iTTIwIDE0aDIiLz48cGF0aCBkPSJNMTUgMTN2MiIvPjxwYXRoIGQ9Ik05IDEzdjIiLz48L3N2Zz4="
      order: 1
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "anthropic/claude-sonnet-4.5"
    
    - name: "openai-gpt5-2"
      label: "GPT-5.2"
      description: "Sehr gut für komplexe Aufgaben und mehrstufige Problemlösung. Von OpenAI."
      group: "Beliebte Premium-Modelle"
      order: 2
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "openai/gpt-5.2"
    
    - name: "mistral-large-2411"
      label: "Mistral Large 2411"
      description: "Sehr beliebt bei europäischen Nutzern. Europäisches Unternehmen (französisch)."
      group: "Beliebte Premium-Modelle"
      order: 3
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "mistralai/mistral-large-2411"
    
    - name: "z-ai-glm-4.7"
      label: "GLM 4.7"
      description: "Sehr gut im logischen Denken und komplexen Aufgaben. Fortgeschrittenes Sprachverständnis."
      group: "Beliebte Premium-Modelle"
      order: 4
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "glm/glm-4.7"
    
    - name: "google-gemini-2.5-flash-lite"
      label: "Gemini 2.5 Flash Lite"
      description: "Schnell und kostengünstig. Optimiert für schnelle Antworten bei guter Qualität."
      group: "Beliebte Premium-Modelle"
      order: 5
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "google/gemini-2.5-flash-lite"


webSearch:
  enabled: true
  searchProvider: "searxng"
  searxngInstanceUrl: "$${LIBRECHAT_SEARXNG_URL}"
  searxngApiKey: "$${LIBRECHAT_SEARXNG_API_KEY}"
  scraperProvider: "firecrawl"
  firecrawlApiKey: "$${FIRECRAWL_API_KEY}"
  firecrawlApiUrl: "$${FIRECRAWL_API_URL}"
  firecrawlVersion: "$${FIRECRAWL_VERSION}"
  jinaApiKey: "$${LIBRECHAT_JINA_API_KEY}"
  jinaApiUrl: "$${LIBRECHAT_JINA_API_URL}"
  rerankerType: "jina"
  scraperTimeout: 7500
  safeSearch: 1

registration:
  allowedDomains:
    - correctiv.org
    - faktenforum.org
  # Optional: Social Login Providers (default: all disabled)
  # socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple', 'saml']

# Balance System (disabled - for cost-based limits)
# balance:
#   enabled: false
#   startBalance: 20000        # Starting balance for new users
#   autoRefillEnabled: false   # Automatic refill
#   refillIntervalValue: 30    # Interval value
#   refillIntervalUnit: 'days' # Interval unit (days, weeks, months)
#   refillAmount: 10000        # Refill amount

# Transactions (disabled - for transaction logs)
# Default: true (enabled), automatically enabled when balance.enabled: true
# transactions:
#   enabled: false

# Speech / Voice Features (disabled - TTS/STT)
# speech:
#   tts:
#     openai:
#       url: ''
#       apiKey: '${TTS_API_KEY}'
#       model: ''
#       voices: ['']
#   stt:
#     openai:
#       url: ''
#       apiKey: '${STT_API_KEY}'
#       model: ''

# Cloudflare Turnstile CAPTCHA (disabled)
# turnstile:
#   siteKey: "your-site-key-here"
#   options:
#     language: "auto"    # "auto" or ISO 639-1 code (e.g. "de")
#     size: "normal"      # "normal", "compact", "flexible", "invisible"

# Rate Limits (disabled - for upload/import limits)
# rateLimits:
#   fileUploads:
#     ipMax: 100                    # Max uploads per IP
#     ipWindowInMinutes: 60         # Time window for IP limit
#     userMax: 50                   # Max uploads per user
#     userWindowInMinutes: 60       # Time window for user limit
#   conversationsImport:
#     ipMax: 100                    # Max imports per IP
#     ipWindowInMinutes: 60         # Time window for IP limit
#     userMax: 50                   # Max imports per user
#     userWindowInMinutes: 60       # Time window for user limit

# File Config (disabled - granular upload configuration)
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5                # Max files per request
#       fileSizeLimit: 10           # Max size per file (MB)
#       totalSizeLimit: 50          # Max total size (MB)
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true              # Disables uploads for OpenAI endpoint
#     default:
#       totalSizeLimit: 20          # Default total size (MB)
#   serverFileSizeLimit: 100        # Global server limit (MB)
#   avatarSizeLimit: 2              # Avatar size limit (MB)
#   imageGeneration:
#     percentage: 100               # Image size in percentage
#     px: 1024                      # Image size in pixels
#   clientImageResize:
#     enabled: false                # Client-side image compression
#     maxWidth: 1900                # Max width (px)
#     maxHeight: 1900               # Max height (px)
#     quality: 0.92                 # JPEG quality (0.0-1.0)

# MCP Servers Interface Config (default: use: true, create: true, share: false)
# interface:
#   mcpServers:
#     use: true       # Users can use MCP servers (default: true)
#     create: true    # Users can create MCP servers (default: true)
#     share: false    # Users can share MCP servers (default: false)

# Temporary Chat Retention (disabled - automatic deletion)
# interface:
#   temporaryChatRetention: 720  # Hours (min: 1, max: 8760, default: 720 = 30 days)

# Actions Domain Restrictions (disabled - SSRF protection for Agent Actions)
# SECURITY: If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs)
# To allow internal targets, they MUST be explicitly added to allowedDomains
# Supports wildcards: '*.example.com' and protocol/port restrictions: 'https://api.example.com:8443'
# actions:
#   allowedDomains:
#     - 'swapi.dev'
#     - 'librechat.ai'
#     - 'google.com'
#     # - 'http://10.225.26.25:7894'  # Internal IP with protocol/port (uncomment if needed)

# MCP Settings (SSRF protection for MCP Server Remote Transports)
# SECURITY: If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs)
# To allow internal targets like host.docker.internal, they MUST be explicitly added
# Supports wildcards: '*.example.com' matches 'api.example.com', 'staging.example.com', etc.
# Supports protocol/port restrictions: 'https://api.example.com:8443'
mcpSettings:
  allowedDomains:
    - 'host.docker.internal'    # Docker host access (required for Docker setups)
    - 'localhost'               # Local development
    - 'mcp-calculator'           # MCP Calculator service (Docker network)
    - 'mcp-image-gen'            # MCP Image Generation service (Docker network)
    - 'mcp-firecrawl'           # MCP Firecrawl service (Docker network)
    - 'mcp-openstreetmap'       # MCP OpenStreetMap service (Docker network)
    - 'mcp-weather'             # MCP Weather service (Docker network)
    - 'mcp-playwright'          # MCP Playwright service (Docker network)
    - 'mcp-db-timetable'        # MCP DB Timetable service (Docker network)
    - 'mcp-stackoverflow'       # MCP StackOverflow service (Docker network)
    - 'mcp-npm-search'           # MCP npm Search service (Docker network)
    - 'api.githubcopilot.com'   # GitHub MCP Server (remote hosted)
    - 'mcp.mapbox.com'           # Mapbox MCP Server (remote hosted)
    # - '*.example.com'           # Wildcard subdomain
    # - 'https://secure.api.com'  # Protocol-restricted
    # - 'http://internal:8080'    # Protocol and port restricted
    # n8n Integration (uncomment when MCP bridge is ready)
    # - 'http://n8n:5678'        # Internal n8n service (Docker network)
    # - 'https://n8n.${DOMAIN}'  # External n8n URL (production)

# MCP Calculator Server
mcpServers:
  calculator:
    type: streamable-http
    url: http://mcp-calculator:3000/mcp
    title: Rechner
    description: Mathematische Berechnungen und Rechenoperationen
    iconPath: /images/mcp-calculator-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: false
    serverInstructions: true

  image-gen:
    type: streamable-http
    url: http://mcp-image-gen:3001/mcp
    title: Bildgenerierung
    description: Bilder aus Textbeschreibungen erstellen
    iconPath: /images/mcp-image-gen-icon.svg
    initTimeout: 180000
    chatMenu: false
    startup: true
    serverInstructions: true

  openstreetmap:
    type: streamable-http
    url: http://mcp-openstreetmap:3004/mcp
    title: OpenStreetMap
    description: Geografische Suche, Routenplanung und Standortinformationen
    iconPath: /images/mcp-openstreetmap-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  weather:
    type: streamable-http
    url: http://mcp-weather:3005/mcp
    title: Wetter
    description: Aktuelle Wetterdaten, Luftqualität und Zeitzoneninformationen
    iconPath: /images/mcp-weather-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  playwright:
    type: streamable-http
    url: http://mcp-playwright:3006/mcp
    title: Browser Automatisierung
    description: Webseiten durchsuchen, interagieren und automatisieren
    iconPath: /images/mcp-playwright-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: false
    serverInstructions: true

  db-timetable:
    type: streamable-http
    url: http://mcp-db-timetable:3007/sse
    title: DB Fahrplan
    description: Aktuelle Fahrpläne, Stationssuche und Zugverbindungen der Deutschen Bahn
    iconPath: /images/mcp-db-timetable-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  stackoverflow:
    type: streamable-http
    url: http://mcp-stackoverflow:3008/mcp
    title: Stack Overflow
    description: Programmierlösungen und Fehlerbehebung finden
    iconPath: /images/mcp-stackoverflow-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  npm-search:
    type: streamable-http
    url: http://mcp-npm-search:3009/mcp
    title: npm Suche
    description: npm-Pakete durchsuchen und finden
    iconPath: /images/mcp-npm-search-icon.svg
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  github:
    type: streamable-http
    url: https://api.githubcopilot.com/mcp/
    title: GitHub
    description: Repository-Verwaltung, Issues, Pull Requests und Code-Analyse
    iconPath: /images/mcp-github-icon.svg
    headers:
      Authorization: "Bearer ${MCP_GITHUB_PAT}"
      X-MCP-Readonly: "true"
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  mapbox:
    type: streamable-http
    url: https://mcp.mapbox.com/mcp
    title: Mapbox
    description: Geografische Suche, Routenplanung, Geocoding und Kartenvisualisierung
    iconPath: /images/mcp-mapbox-icon.svg
    headers:
      Authorization: "Bearer ${MCP_MAPBOX_ACCESS_TOKEN}"
    initTimeout: 120000
    chatMenu: false
    startup: true
    serverInstructions: true

  # This MCP tool is very helpful when special URLs need to be read. Unfortunately, the connection to the MCP server is currently too unstable and has therefore been deactivated for the time being.
  # firecrawl:
  #   type: streamable-http
  #   url: http://mcp-firecrawl:3003/mcp
  #   title: Web Scraping
  #   description: Webseiten scrapen, durchsuchen und analysieren
  #   iconPath: /images/mcp-firecrawl-icon.svg
  #   initTimeout: 120000
  #   chatMenu: true
  #   startup: true
  #   serverInstructions: true

# n8n MCP Server Integration (Future - disabled)
# To integrate n8n workflows with LibreChat Agents via MCP:
# 1. Create an HTTP-based MCP server bridge that translates MCP calls to n8n webhook requests
# 2. Configure the MCP server below as a streamable-http type
# 3. Add n8n domain to mcpSettings.allowedDomains (see above)
# Example configuration (uncomment when ready):
#   n8n:
#     type: streamable-http
#     url: http://n8n:5678/mcp  # Internal Docker network URL
#     # Or use external URL: https://n8n.${DOMAIN}/mcp
#     headers:
#       X-User-ID: "{{LIBRECHAT_USER_ID}}"
#       Authorization: "Bearer ${N8N_API_KEY}"
#     timeout: 30000
#     serverInstructions: true
#     chatMenu: true  # Show in chat dropdown (or false for agents only)

# OCR Configuration (Optical Character Recognition)
# Requires: LIBRECHAT_OCR_API_KEY environment variable set with your Mistral API key
ocr:
  mistralModel: "mistral-ocr-latest"
  apiKey: "${OCR_API_KEY}"
  baseURL: "${OCR_BASEURL}"
  strategy: "mistral_ocr"

# File Configuration - Define supported MIME types for OCR and other file operations
fileConfig:
  ocr:
    # Mistral OCR supports: PNG, JPEG/JPG, AVIF (images) + PDF, DOCX, PPTX (documents)
    # Using image/.* to allow all image formats - unsupported ones will fall back to text parsing
    supportedMimeTypes:
      - "image/.*"
      - "application/pdf"
      - "application/vnd.openxmlformats-officedocument.wordprocessingml.document"  # DOCX
      - "application/vnd.openxmlformats-officedocument.presentationml.presentation"  # PPTX
      - "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"  # XLSX
  text:
    # All text/* MIME types (covers: plain, javascript, python, html, markdown, css, csv, etc.)
    # Plus specific application/* MIME types for text-based formats
    supportedMimeTypes:
      - "text/.*"
      - "application/json"
      - "application/yaml"
      - "application/csv"
      - "application/typescript"
      - "application/sql"
      - "application/xml"
      - "application/x-sh"
      - "application/vnd.coffeescript"
  stt:
    # Audio formats supported by Azure OpenAI STT and other STT providers
    # Formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm, aac, opus, wma
    supportedMimeTypes:
      - "^audio/(mp3|mpeg|mpeg3|mp4|m4a|mpga|wav|wave|x-wav|ogg|vorbis|webm|flac|x-flac|aac|wma|opus)$"

# File Strategy (Granular) - disabled (default: "local" for all file types)
# Allows different storage strategies for different file types
# If not specified, all file types default to "local"
# Priority: specific type > fileStrategies.default > fileStrategy > "local"
# Available strategies: "local", "s3", "firebase", "azure_blob"
fileStrategies:
  default: "local"
  avatar: "local"
  image: "local"
  document: "local"
