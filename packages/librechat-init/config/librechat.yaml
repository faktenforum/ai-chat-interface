version: 1.3.1
cache: true

interface:
  customWelcome: '$${LIBRECHAT_CUSTOM_WELCOME}'
  privacyPolicy:
    externalUrl: '$${LIBRECHAT_PRIVACY_POLICY_URL}'
    openNewTab: true
  termsOfService:
    externalUrl: '$${LIBRECHAT_TERMS_OF_SERVICE_URL}'
    openNewTab: true
    modalAcceptance: true
    modalTitle: 'Kleingedrucktes'
    modalContent: |
      # Nutzungsbedingungen

      **Wichtiger Hinweis zu KI-generierten Antworten**
      Alle Antworten dieses KI-Systems sollten stets von Menschen überprüft werden. KI-generierte Inhalte können Fehler enthalten und sollten nicht als alleinige Quelle für wichtige Entscheidungen verwendet werden.

      **Datenverarbeitung und Hosting**
      Wir bemühen uns, so viele Komponenten wie möglich selbst zu hosten. Aktuell nutzen wir noch externe Dienste wie OpenRouter, wodurch Daten derzeit an Server in den USA übertragen werden. Unser Ziel ist es, vollständig auf selbst gehostete oder europäische Dienste umzustellen.
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: true
  fileCitations: true
  fileSearch: true
  search: true

memory:
  disabled: false
  personalize: true
  tokenLimit: 2000
  messageWindowSize: 5
  # Memory categories for journalism and fact-checking workflow
  # Restricts memory storage to these structured categories for better consistency
  validKeys:
    # User preferences and communication style
    - "preferences"
    # Work-related: role, organization, department, responsibilities
    - "work_info"
    # Personal information: name, location, contact preferences
    - "personal_info"
    # Current projects, research topics, ongoing investigations
    - "projects"
    # Fact-checking specific: methods, verification approaches, source preferences
    - "factcheck_info"
    # Research context: background info, historical context, related investigations
    - "research_context"
    # Preferred sources, verification methods, trusted outlets
    - "sources"
    # Output format preferences: article style, citation format, structure
    - "output_format"
    # Important deadlines, publication dates, milestones
    - "deadlines"
    # Expertise areas, specializations, domain knowledge
    - "expertise"
    # Final results, conclusions, verified facts from completed fact-checks
    - "results"
  agent:
    provider: "OpenRouter"
    # Open Source model optimized for Memory tasks with better function calling precision
    # deepseek/deepseek-chat: Excellent function calling, better at following instructions precisely
    # Alternative: mistralai/mistral-large-2411 (European, good function calling)
    model: "deepseek/deepseek-chat"
    instructions: |
      Store ONLY substantial, reusable info using validKeys categories. NEVER: greetings, casual chat, trivial mentions, obvious statements. Store: preferences (communication style, topics, workflow), work_info (role, org, responsibilities), personal_info (name, location - only if explicitly shared), projects (current research/investigations), factcheck_info (verification methods), research_context (background, related work), sources (preferred outlets), output_format (article style), deadlines (important dates), expertise (specializations), results (verified facts, conclusions). Must be reusable across conversations. Delete outdated/corrected info promptly. If only greetings/casual chat/no substantial info, END IMMEDIATELY without tools. UPDATE STRATEGY: Check existing memories first. If matching category/key exists, UPDATE with `set_memory` by merging old+new info. Only create new if no match. NEVER delete+recreate. Token limit: 2000 per value.
    model_parameters:
      # Lower temperature for more precise, deterministic function calling decisions
      # 0.2 provides better precision for memory task decisions
      temperature: 0.2
      # top_p: 0.8 provides controlled sampling - balances precision with flexibility
      # Lower than 0.9 for more focused token selection in memory tasks
      top_p: 0.8

endpoints:
  # Agents configuration
  agents:
    disableBuilder: false
    capabilities:
      - "execute_code"
      - "file_search"
      - "actions"
      - "artifacts"
      - "chain"
      - "context"
      - "ocr"
      - "tools"
      - "web_search"
  
  custom:
    - name: OpenRouter
      apiKey: "$${OPENROUTER_KEY}"
      baseURL: "$${OPENROUTER_BASE_URL}"
      models:
        # Mix of Open Source and proprietary models - Fallback list if fetch fails or fetch is disabled
        # Sorted by Top Weekly popularity
        default: [
          "anthropic/claude-sonnet-4.5",      # Top proprietary model
          "deepseek/deepseek-v3.2",           # Best Open Source
          "google/gemini-2.5-flash-lite",    # Google's lightweight reasoning model, optimized for speed and cost
          "meta-llama/llama-3.3-70b-instruct", # Meta's latest, very popular
          "openai/gpt-5.2",                   # Latest GPT-5 series
          "xiaomi/mimo-v2-flash",             # Popular open-source model
          "deepseek/deepseek-chat",           # Excellent for coding
          "mistralai/mistral-large-2411",     # European option (French)
          "mistralai/mistral-nemo"            # European option (French, smaller)
        ]
        fetch: true
      titleConvo: true
      summarize: true
      headers:
        HTTP-Referer: "$${OPENROUTER_SITE_URL}"
        X-Title: "$${OPENROUTER_APP_NAME}"

# Model Specs: Define default model for new users
# This prevents "My Agents" from being selected when users have no agents
# Note: Memory function uses a separate model (configured in memory.agent section)
# Chat models don't need Function Calling for Memory - Memory works independently
# Models sorted by OpenRouter Top Weekly popularity (https://openrouter.ai/models?order=top-weekly)
# Mix of Open Source and proprietary models, European models prioritized where available
modelSpecs:
  list:
    # ==========================================
    # Vision Models (Open Source)
    # ==========================================
    - name: "qwen2.5-vl-72b"
      label: "Qwen2.5-VL 72B"
      description: "Höchste Qualität für Gespräche und Bildverständnis. Kann Bilder analysieren und gleichzeitig natürlich chatten. Von Qwen."
      group: "Vision Models (Open Source)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWV5ZS1pY29uIGx1Y2lkZS1leWUiPjxwYXRoIGQ9Ik0yLjA2MiAxMi4zNDhhMSAxIDAgMCAxIDAtLjY5NiAxMC43NSAxMC43NSAwIDAgMSAxOS44NzYgMCAxIDEgMCAwIDEgMCAuNjk2IDEwLjc1IDEwLjc1IDAgMCAxLTE5Ljg3NiAwIi8+PGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iMyIvPjwvc3ZnPg=="
      order: 1
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "qwen/qwen2.5-vl-72b-instruct"
    
    - name: "qwen2.5-vl-32b"
      label: "Qwen2.5-VL 32B"
      description: "Gute Balance aus Qualität und Geschwindigkeit. Versteht Bilder und führt natürliche Gespräche. Von Qwen."
      group: "Vision Models (Open Source)"
      order: 2
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "qwen/qwen2.5-vl-32b-instruct"
    
    - name: "llama-3.2-vision-90b"
      label: "Llama 3.2 Vision 90B"
      description: "Sehr gute Gesprächsqualität mit Bildverständnis. Kann Bilder beschreiben und analysieren. Von Meta (Llama-Serie)."
      group: "Vision Models (Open Source)"
      order: 3
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "meta-llama/llama-3.2-90b-vision-instruct"
    
    # ==========================================
    # Vision Models (Proprietary) - Chat Only
    # ==========================================
    - name: "google-gemini-2.5-flash-lite"
      label: "Gemini 2.5 Flash Lite"
      description: "Schnell und kostengünstig. Optimiert für schnelle Antworten bei guter Qualität. Unterstützt Vision. Von Google."
      group: "Vision Models (Proprietary)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWV5ZS1pY29uIGx1Y2lkZS1leWUiPjxwYXRoIGQ9Ik0yLjA2MiAxMi4zNDhhMSAxIDAgMCAxIDAtLjY5NiAxMC43NSAxMC43NSAwIDAgMSAxOS44NzYgMCAxIDEgMCAwIDEgMCAuNjk2IDEwLjc1IDEwLjc1IDAgMCAxLTE5Ljg3NiAwIi8+PGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iMyIvPjwvc3ZnPg=="
      order: 1
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "google/gemini-2.5-flash-lite"
    
    # ==========================================
    # Universal Models (Proprietary) - Vision + Tools
    # ==========================================
    - name: "claude-sonnet-4.5"
      label: "Claude Sonnet 4.5"
      description: "Eines der besten Modelle für komplexe Aufgaben und Programmierung. Optimiert für praktische Anwendungen. Unterstützt Vision und Tools. Von Anthropic."
      group: "Universal Models (Proprietary)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWJvdC1pY29uIGx1Y2lkZS1ib3QiPjxwYXRoIGQ9Ik0xMiA4VjRIOCIvPjxyZWN0IHdpZHRoPSIxNiIgaGVpZ2h0PSIxMiIgeD0iNCIgeT0iOCIgcng9IjIiLz48cGF0aCBkPSJNMiAxNGgyIi8+PHBhdGggZD0iTTIwIDE0aDIiLz48cGF0aCBkPSJNMTUgMTN2MiIvPjxwYXRoIGQ9Ik05IDEzdjIiLz48L3N2Zz4="
      order: 1
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "anthropic/claude-sonnet-4.5"
    
    # ==========================================
    # Text Models (Open Source) - Chat Only
    # ==========================================
    - name: "llama-3.1-8b"
      label: "Llama 3.1 8B"
      description: "Schnell und effizient. Gute Wahl für schnelle Antworten. Von Meta (Llama-Serie)."
      group: "Text Models (Open Source)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLW1lc3NhZ2Utc3F1YXJlLWljb24gbHVjaWRlLW1lc3NhZ2Utc3F1YXJlIj48cGF0aCBkPSJNMjIgMTdhMiAyIDAgMCAxLTIgMkg2LjgyOGEyIDIgMCAwIDAtMS40MTQuNTg2bC0yLjIwMiAyLjIwMkEuNzEuNzEgMCAwIDEgMiAyMS4yODZWNWEyIDIgMCAwIDEgMi0yaDE2YTIgMiAwIDAgMSAyIDJ6Ii8+PC9zdmc+"
      order: 1
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "meta-llama/llama-3.1-8b-instruct"
    
    # ==========================================
    # Text Models with Tools (Open Source)
    # ==========================================
    - name: "deepseek-v3.2"
      label: "DeepSeek V3.2"
      description: "Kann sehr lange Gespräche führen und komplexe Aufgaben lösen. Sehr gut im logischen Denken. Von DeepSeek."
      group: "Text Models with Tools (Open Source)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWJvdC1tZXNzYWdlLXNxdWFyZS1pY29uIGx1Y2lkZS1ib3QtbWVzc2FnZS1zcXVhcmUiPjxwYXRoIGQ9Ik0xMiA2VjJIOCIvPjxwYXRoIGQ9Ik0xNSAxMXYyIi8+PHBhdGggZD0iTTIgMTJoMiIvPjxwYXRoIGQ9Ik0yMCAxMmgyIi8+PHBhdGggZD0iTTIwIDE2YTIgMiAwIDAgMS0yIDJIOC44MjhhMiAyIDAgMCAwLTEuNDE0LjU4NmwtMi4yMDIgMi4yMDJBLjcxLjcxIDAgMCAxIDQgMjAuMjg2VjhhMiAyIDAgMCAxIDItMmgxMmEyIDIgMCAwIDEgMiAyeiIvPjxwYXRoIGQ9Ik05IDExdjIiLz48L3N2Zz4="
      order: 1
      default: true
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "deepseek/deepseek-v3.2"
    
    - name: "llama-3.3-70b"
      label: "Llama 3.3 70B"
      description: "Sehr beliebt für allgemeine Gespräche und Aufgaben. Von Meta (Llama-Serie)."
      group: "Text Models with Tools (Open Source)"
      order: 2
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "meta-llama/llama-3.3-70b-instruct"
    
    - name: "xiaomi-mimo-v2-flash"
      label: "MiMo-V2-Flash"
      description: "Kann sehr lange Gespräche führen. Besonders gut für Wissensthemen, Wissenschaft und Finanzen. Von Xiaomi."
      group: "Text Models with Tools (Open Source)"
      order: 3
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "xiaomi/mimo-v2-flash"
    
    - name: "deepseek-chat-67b"
      label: "DeepSeek Chat 67B"
      description: "Sehr beliebt, besonders gut für Programmierung und Code-Erstellung. Von DeepSeek."
      group: "Text Models with Tools (Open Source)"
      order: 4
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "deepseek/deepseek-chat"
    
    # ==========================================
    # Text Models (Proprietary) - Chat Only
    # ==========================================
    - name: "openai-gpt5-mini"
      label: "GPT-5 Mini"
      description: "Schnell und effizient, dabei hochwertige Antworten. Optimiert für Geschwindigkeit. Von OpenAI (GPT-5-Serie)."
      group: "Text Models (Proprietary)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLW1lc3NhZ2Utc3F1YXJlLWxvY2staWNvbiBsdWNpZGUtbWVzc2FnZS1zcXVhcmUtbG9jayI+PHBhdGggZD0iTTIyIDguNVY1YTIgMiAwIDAgMC0yLTJINGEyIDIgMCAwIDAtMiAydjE2LjI4NmEuNzEuNzEgMCAwIDAgMS4yMTIuNTAybDIuMjAyLTIuMjAyQTIgMiAwIDAgMSA2LjgyOCAxOUgxMCIvPjxwYXRoIGQ9Ik0yMCAxNXYtMmEyIDIgMCAwIDAtNCAwdjIiLz48cmVjdCB4PSIxNCIgeT0iMTUiIHdpZHRoPSI4IiBoZWlnaHQ9IjUiIHJ4PSIxIi8+PC9zdmc+"
      order: 1
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "openai/gpt-5-mini"
    
    - name: "mistral-nemo"
      label: "Mistral Nemo"
      description: "Unterstützt mehrere Sprachen. Von Mistral und NVIDIA. Europäisches Unternehmen (französisch)."
      group: "Text Models (Proprietary)"
      order: 2
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "mistralai/mistral-nemo"
    
    # ==========================================
    # Text Models with Tools (Proprietary)
    # ==========================================
    - name: "openai-gpt5-2"
      label: "GPT-5.2"
      description: "Sehr gut für komplexe Aufgaben und mehrstufige Problemlösung. Von OpenAI (GPT-5-Serie)."
      group: "Text Models with Tools (Proprietary)"
      groupIcon: "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLWJvdC1tZXNzYWdlLXNxdWFyZS1pY29uIGx1Y2lkZS1ib3QtbWVzc2FnZS1zcXVhcmUiPjxwYXRoIGQ9Ik0xMiA2VjJIOCIvPjxwYXRoIGQ9Ik0xNSAxMXYyIi8+PHBhdGggZD0iTTIgMTJoMiIvPjxwYXRoIGQ9Ik0yMCAxMmgyIi8+PHBhdGggZD0iTTIwIDE2YTIgMiAwIDAgMS0yIDJIOC44MjhhMiAyIDAgMCAwLTEuNDE0LjU4NmwtMi4yMDIgMi4yMDJBLjcxLjcxIDAgMCAxIDQgMjAuMjg2VjhhMiAyIDAgMCAxIDItMmgxMmEyIDIgMCAwIDEgMiAyeiIvPjxwYXRoIGQ9Ik05IDExdjIiLz48L3N2Zz4="
      order: 1
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "openai/gpt-5.2"
    
    - name: "mistral-large-2411"
      label: "Mistral Large 2411"
      description: "Sehr beliebt bei europäischen Nutzern. Von Mistral. Europäisches Unternehmen (französisch)."
      group: "Text Models with Tools (Proprietary)"
      order: 2
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "mistralai/mistral-large-2411"
    
    - name: "z-ai-glm-4.7"
      label: "GLM 4.7"
      description: "Sehr gut im logischen Denken und komplexen Aufgaben. Fortgeschrittenes Sprachverständnis. Von Z.AI."
      group: "Text Models with Tools (Proprietary)"
      order: 3
      webSearch: true
      fileSearch: true
      preset:
        endpoint: "OpenRouter"
        endpointType: "custom"
        model: "glm/glm-4.7"


webSearch:
  enabled: true
  searchProvider: "searxng"
  searxngInstanceUrl: "$${LIBRECHAT_SEARXNG_URL}"
  searxngApiKey: "$${LIBRECHAT_SEARXNG_API_KEY}"
  scraperProvider: "firecrawl"
  firecrawlApiKey: "$${FIRECRAWL_API_KEY}"
  firecrawlApiUrl: "$${FIRECRAWL_API_URL}"
  firecrawlVersion: "$${FIRECRAWL_VERSION}"
  jinaApiKey: "$${LIBRECHAT_JINA_API_KEY}"
  jinaApiUrl: "$${LIBRECHAT_JINA_API_URL}"
  rerankerType: "jina"
  scraperTimeout: 7500
  safeSearch: 1

registration:
  allowedDomains:
    - correctiv.org
    - faktenforum.org
  # Optional: Social Login Providers (default: all disabled)
  # socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple', 'saml']

# Balance System (disabled - for cost-based limits)
# balance:
#   enabled: false
#   startBalance: 20000        # Starting balance for new users
#   autoRefillEnabled: false   # Automatic refill
#   refillIntervalValue: 30    # Interval value
#   refillIntervalUnit: 'days' # Interval unit (days, weeks, months)
#   refillAmount: 10000        # Refill amount

# Transactions (disabled - for transaction logs)
# Default: true (enabled), automatically enabled when balance.enabled: true
# transactions:
#   enabled: false

# Speech / Voice Features (disabled - TTS/STT)
# speech:
#   tts:
#     openai:
#       url: ''
#       apiKey: '${TTS_API_KEY}'
#       model: ''
#       voices: ['']
#   stt:
#     openai:
#       url: ''
#       apiKey: '${STT_API_KEY}'
#       model: ''

# Cloudflare Turnstile CAPTCHA (disabled)
# turnstile:
#   siteKey: "your-site-key-here"
#   options:
#     language: "auto"    # "auto" or ISO 639-1 code (e.g. "de")
#     size: "normal"      # "normal", "compact", "flexible", "invisible"

# Rate Limits (disabled - for upload/import limits)
# rateLimits:
#   fileUploads:
#     ipMax: 100                    # Max uploads per IP
#     ipWindowInMinutes: 60         # Time window for IP limit
#     userMax: 50                   # Max uploads per user
#     userWindowInMinutes: 60       # Time window for user limit
#   conversationsImport:
#     ipMax: 100                    # Max imports per IP
#     ipWindowInMinutes: 60         # Time window for IP limit
#     userMax: 50                   # Max imports per user
#     userWindowInMinutes: 60       # Time window for user limit

# File Config (disabled - granular upload configuration)
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5                # Max files per request
#       fileSizeLimit: 10           # Max size per file (MB)
#       totalSizeLimit: 50          # Max total size (MB)
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true              # Disables uploads for OpenAI endpoint
#     default:
#       totalSizeLimit: 20          # Default total size (MB)
#   serverFileSizeLimit: 100        # Global server limit (MB)
#   avatarSizeLimit: 2              # Avatar size limit (MB)
#   imageGeneration:
#     percentage: 100               # Image size in percentage
#     px: 1024                      # Image size in pixels
#   clientImageResize:
#     enabled: false                # Client-side image compression
#     maxWidth: 1900                # Max width (px)
#     maxHeight: 1900               # Max height (px)
#     quality: 0.92                 # JPEG quality (0.0-1.0)

# MCP Servers Interface Config (default: use: true, create: true, share: false)
# interface:
#   mcpServers:
#     use: true       # Users can use MCP servers (default: true)
#     create: true    # Users can create MCP servers (default: true)
#     share: false    # Users can share MCP servers (default: false)

# Temporary Chat Retention (disabled - automatic deletion)
# interface:
#   temporaryChatRetention: 720  # Hours (min: 1, max: 8760, default: 720 = 30 days)

# Actions Domain Restrictions (disabled - SSRF protection for Agent Actions)
# SECURITY: If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs)
# To allow internal targets, they MUST be explicitly added to allowedDomains
# Supports wildcards: '*.example.com' and protocol/port restrictions: 'https://api.example.com:8443'
# actions:
#   allowedDomains:
#     - 'swapi.dev'
#     - 'librechat.ai'
#     - 'google.com'
#     # - 'http://10.225.26.25:7894'  # Internal IP with protocol/port (uncomment if needed)

# MCP Settings (disabled - SSRF protection for MCP Server Remote Transports)
# SECURITY: If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs)
# To allow internal targets like host.docker.internal, they MUST be explicitly added
# Supports wildcards: '*.example.com' matches 'api.example.com', 'staging.example.com', etc.
# Supports protocol/port restrictions: 'https://api.example.com:8443'
# mcpSettings:
#   allowedDomains:
#     - 'host.docker.internal'    # Docker host access (required for Docker setups)
#     - 'localhost'               # Local development
#     - '*.example.com'           # Wildcard subdomain
#     - 'https://secure.api.com'  # Protocol-restricted
#     - 'http://internal:8080'    # Protocol and port restricted

# OCR Configuration (Optical Character Recognition)
# Requires: LIBRECHAT_OCR_API_KEY environment variable set with your Mistral API key
ocr:
  mistralModel: "mistral-ocr-latest"
  apiKey: "${OCR_API_KEY}"
  baseURL: "${OCR_BASEURL}"
  strategy: "mistral_ocr"

# File Configuration - Define supported MIME types for OCR and other file operations
fileConfig:
  ocr:
    supportedMimeTypes:
      - "image/.*"
      - "application/pdf"
  text:
    supportedMimeTypes:
      - "text/.*"
      - "application/json"
      - "application/x-yaml"
  stt:
    supportedMimeTypes:
      - "audio/.*"

# File Strategy (Granular) - disabled (default: "local" for all file types)
# Allows different storage strategies for different file types
# If not specified, all file types default to "local"
# Priority: specific type > fileStrategies.default > fileStrategy > "local"
# Available strategies: "local", "s3", "firebase", "azure_blob"
fileStrategies:
  default: "local"
  avatar: "local"
  image: "local"
  document: "local"
