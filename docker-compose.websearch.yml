services:
  searxng-config-init:
    image: alpine:latest
    container_name: searxng-config-init
    restart: "no"
    volumes:
      - searxng-config:/etc/searxng
    command:
      - sh
      - -c
      - |
        echo "Generating SearXNG configuration..."
        
        cat > /etc/searxng/settings.yml << 'CONFIG_EOF'
        use_default_settings:
          engines:
            remove:
              - ahmia
              - torch
        server:
          # Secret key from environment variable for security
          secret_key: "${SEARXNG_SECRET_KEY}"
          limiter: false
          image_proxy: true
        search:
          formats:
            - html
            - json
          default_lang: "${SEARXNG_DEFAULT_LANG:-de}"
        # Bot detection configuration for internal Docker network access
        # LibreChat accesses SearXNG directly (container-to-container) without X-Forwarded-For headers
        # We trust Docker's internal networks to allow LibreChat API access
        botdetection:
          enabled: true
          # Trust Docker's internal network ranges
          # This allows LibreChat (and other internal services) to access SearXNG
          # without being blocked by bot detection
          trusted_proxies:
            - "172.16.0.0/12"  # Docker default bridge network range
            - "10.0.0.0/8"     # Docker custom networks (app-net, traefik-net, etc.)
            - "192.168.0.0/16" # Docker custom networks
            - "172.17.0.0/16"  # Docker default bridge
            - "172.18.0.0/16"  # Docker networks
            - "172.19.0.0/16"  # Docker networks
            - "172.20.0.0/16"  # Docker networks
            - "172.21.0.0/16"  # Docker networks
        # Enable additional search engines with weighting for better AI results
        engines:
          # General search engines (weighted for relevance)
          - name: google
            disabled: false
            weight: 2.0
          - name: bing
            disabled: false
            weight: 1.5
          - name: duckduckgo
            disabled: false
            weight: 1.5
          # Wikipedia (high priority for factual information)
          - name: wikipedia
            disabled: false
            weight: 3.0
          # IT & Development
          - name: github
            disabled: false
            weight: 1.0
          - name: npm
            disabled: false
            weight: 1.0
          # Images
          - name: pixabay images
            disabled: false
            weight: 1.0
          # Science & Research (high priority for scientific sources)
          - name: openalex
            disabled: false
            weight: 2.5
          - name: springer nature
            inactive: false
            api_key: "${SPRINGER_NATURE_API_KEY:-}"
            weight: 2.5
        # Enable plugins for better search results
        plugins:
          searx.plugins.infinite_scroll.SXNGPlugin:
            active: true
          searx.plugins.tracker_url_remover.SXNGPlugin:
            active: true
          searx.plugins.oa_doi_rewrite.SXNGPlugin:
            active: true
          searx.plugins.hostnames.SXNGPlugin:
            active: true
        # Hostnames configuration for journalism and trusted sources
        hostnames:
          # High priority: Trusted journalism and academic sources
          high_priority:
            # Wikipedia and knowledge bases
            - '(.*\\.)?wikipedia\\.org$'
            - '(.*\\.)?wikidata\\.org$'
            # Academic and government sources
            - '(.*\\.)?edu$'
            - '(.*\\.)?gov$'
            - '(.*\\.)?ac\\.uk$'
            # German quality journalism
            - '(.*\\.)?sueddeutsche\\.de$'
            - '(.*\\.)?faz\\.net$'
            - '(.*\\.)?zeit\\.de$'
            - '(.*\\.)?spiegel\\.de$'
            - '(.*\\.)?taz\\.de$'
            - '(.*\\.)?correctiv\\.org$'
            - '(.*\\.)?faktenforum\\.org$'
            - '(.*\\.)?netzpolitik\\.org$'
            - '(.*\\.)?tagesschau\\.de$'
            - '(.*\\.)?ard\\.de$'
            - '(.*\\.)?zdf\\.de$'
            - '(.*\\.)?deutschlandfunk\\.de$'
            - '(.*\\.)?deutschlandfunknova\\.de$'
            - '(.*\\.)?ndr\\.de$'
            - '(.*\\.)?wdr\\.de$'
            - '(.*\\.)?br\\.de$'
            - '(.*\\.)?mdr\\.de$'
            - '(.*\\.)?swr\\.de$'
            - '(.*\\.)?hr\\.de$'
            - '(.*\\.)?rbb\\.de$'
            - '(.*\\.)?sr\\.de$'
            - '(.*\\.)?radio-bremen\\.de$'
            # International quality journalism
            - '(.*\\.)?nytimes\\.com$'
            - '(.*\\.)?theguardian\\.com$'
            - '(.*\\.)?bbc\\.com$'
            - '(.*\\.)?bbc\\.co\\.uk$'
            - '(.*\\.)?reuters\\.com$'
            - '(.*\\.)?ap\\.org$'
            - '(.*\\.)?apnews\\.com$'
            - '(.*\\.)?washingtonpost\\.com$'
            - '(.*\\.)?wsj\\.com$'
            - '(.*\\.)?ft\\.com$'
            - '(.*\\.)?economist\\.com$'
            - '(.*\\.)?propublica\\.org$'
            - '(.*\\.)?pbs\\.org$'
            - '(.*\\.)?npr\\.org$'
            # Fact-checking organizations
            - '(.*\\.)?snopes\\.com$'
            - '(.*\\.)?factcheck\\.org$'
            - '(.*\\.)?politifact\\.com$'
            - '(.*\\.)?fullfact\\.org$'
            # Scientific and research organizations
            - '(.*\\.)?nature\\.com$'
            - '(.*\\.)?science\\.org$'
            - '(.*\\.)?arxiv\\.org$'
            - '(.*\\.)?doi\\.org$'
            # IT & Technology journalism (German)
            - '(.*\\.)?golem\\.de$'
            - '(.*\\.)?heise\\.de$'
            - '(.*\\.)?linux-magazin\\.de$'
            - '(.*\\.)?linux\\.de$'
            - '(.*\\.)?pro-linux\\.de$'
            - '(.*\\.)?linux-community\\.de$'
            # IT & Technology journalism (International)
            - '(.*\\.)?arstechnica\\.com$'
            - '(.*\\.)?techcrunch\\.com$'
            - '(.*\\.)?theverge\\.com$'
            - '(.*\\.)?wired\\.com$'
            - '(.*\\.)?zdnet\\.com$'
            # Open Source & Linux communities
            - '(.*\\.)?omgubuntu\\.co\\.uk$'
            - '(.*\\.)?linux\\.ch$'
            - '(.*\\.)?phoronix\\.com$'
            - '(.*\\.)?lwn\\.net$'
            - '(.*\\.)?linuxfoundation\\.org$'
            - '(.*\\.)?opensource\\.org$'
            - '(.*\\.)?gnu\\.org$'
            - '(.*\\.)?fsf\\.org$'
            - '(.*\\.)?debian\\.org$'
            - '(.*\\.)?ubuntu\\.com$'
            - '(.*\\.)?redhat\\.com$'
            - '(.*\\.)?suse\\.com$'
            - '(.*\\.)?archlinux\\.org$'
            - '(.*\\.)?kernel\\.org$'
            - '(.*\\.)?github\\.com$'
            - '(.*\\.)?gitlab\\.com$'
            - '(.*\\.)?sourceforge\\.net$'
            # Democracy & free society projects
            - '(.*\\.)?reporter-ohne-grenzen\\.de$'
            - '(.*\\.)?rsf\\.org$'
            - '(.*\\.)?dekoder\\.org$'
            - '(.*\\.)?n-ost\\.org$'
            - '(.*\\.)?transparency\\.org$'
            - '(.*\\.)?freiheitsrechte\\.org$'
            - '(.*\\.)?digitalcourage\\.de$'
            - '(.*\\.)?ccc\\.de$'
            - '(.*\\.)?eff\\.org$'
            - '(.*\\.)?fsfe\\.org$'
            - '(.*\\.)?wikimedia\\.org$'
            - '(.*\\.)?creativecommons\\.org$'
          # Low priority: Social media and user-generated content
          low_priority:
            - '(.*\\.)?facebook\\.com$'
            - '(.*\\.)?twitter\\.com$'
            - '(.*\\.)?x\\.com$'
            - '(.*\\.)?instagram\\.com$'
            - '(.*\\.)?tiktok\\.com$'
            - '(.*\\.)?reddit\\.com$'
            - '(.*\\.)?youtube\\.com$'
            - '(.*\\.)?youtu\\.be$'
        CONFIG_EOF
        
        # Create minimal limiter.toml to avoid warning (limiter is disabled, but file is still checked)
        cat > /etc/searxng/limiter.toml << 'LIMITER_EOF'
        [botdetection]
        ipv4_prefix = 32
        ipv6_prefix = 48
        trusted_proxies = [
          '127.0.0.0/8',
          '::1',
          '172.16.0.0/12',
          '10.0.0.0/8',
          '192.168.0.0/16',
          '172.17.0.0/16',
          '172.18.0.0/16',
          '172.19.0.0/16',
          '172.20.0.0/16',
          '172.21.0.0/16',
        ]
        [botdetection.ip_limit]
        filter_link_local = false
        link_token = false
        [botdetection.ip_lists]
        block_ip = []
        pass_ip = []
        pass_searxng_org = true
        LIMITER_EOF
        
        chmod 644 /etc/searxng/settings.yml
        chmod 644 /etc/searxng/limiter.toml
        
        echo "SearXNG configuration generated successfully"
        echo "Settings:"
        cat /etc/searxng/settings.yml
        echo ""
        echo "Limiter config:"
        cat /etc/searxng/limiter.toml

  searxng:
    container_name: searxng
    image: searxng/searxng:latest
    restart: always
    volumes:
      - searxng-config:/etc/searxng:ro
    environment:
      SEARXNG_BASE_URL: http://searxng.${DOMAIN:-localhost}/
      SEARXNG_SECRET_KEY: ${SEARXNG_SECRET_KEY}
      SEARXNG_API_KEY: ${LIBRECHAT_SEARXNG_API_KEY:-}
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"
    networks:
      - traefik-net
      - app-net
    depends_on:
      searxng-config-init:
        condition: service_completed_successfully

  playwright-service:
    container_name: firecrawl-playwright
    image: ghcr.io/firecrawl/playwright-service:latest
    restart: always
    user: root
    environment:
      - PORT=3000
    networks:
      - firecrawl-network

  redis:
    container_name: firecrawl-redis
    image: redis:alpine
    restart: always
    command: redis-server --bind 0.0.0.0
    networks:
      - firecrawl-network

  nuq-postgres:
    container_name: firecrawl-postgres
    image: ghcr.io/firecrawl/nuq-postgres:latest
    environment:
      POSTGRES_DB: ${FIRECRAWL_POSTGRES_DB:-firecrawl}
      POSTGRES_USER: ${FIRECRAWL_POSTGRES_USER:-firecrawl}
      POSTGRES_PASSWORD: ${FIRECRAWL_POSTGRES_PASSWORD:-firecrawl}
    command: ["postgres", "-c", "cron.database_name=${FIRECRAWL_POSTGRES_DB:-firecrawl}"]
    restart: always
    volumes:
      - firecrawl_pgdata:/var/lib/postgresql/data
    networks:
      - firecrawl-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U firecrawl || pg_isready -U ${FIRECRAWL_POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # RabbitMQ for Firecrawl job queue. If Docker returns 502 when creating this container,
  # reduce parallel startup load (e.g. start firecrawl stack separately) or increase Docker Desktop resources.
  rabbitmq:
    container_name: firecrawl-rabbitmq
    image: rabbitmq:3-management-alpine
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${FIRECRAWL_RABBITMQ_USER:-firecrawl}
      RABBITMQ_DEFAULT_PASS: ${FIRECRAWL_RABBITMQ_PASSWORD:-firecrawl}
    volumes:
      - firecrawl_rabbitmq_data:/var/lib/rabbitmq
    networks:
      - firecrawl-network
    healthcheck:
      # check_running: broker is fully running (recommended over ping for readiness)
      test: ["CMD", "rabbitmq-diagnostics", "-q", "check_running"]
      interval: 10s
      timeout: 10s
      retries: 6
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "2"

  firecrawl-api:
    container_name: firecrawl-api
    image: ghcr.io/firecrawl/firecrawl:latest
    restart: always
    environment:
      HOST: 0.0.0.0
      PORT: ${FIRECRAWL_INTERNAL_PORT:-3002}
      EXTRACT_WORKER_PORT: ${FIRECRAWL_EXTRACT_WORKER_PORT:-3004}
      WORKER_PORT: ${FIRECRAWL_WORKER_PORT:-3005}
      NUM_WORKERS_PER_QUEUE: ${FIRECRAWL_NUM_WORKERS:-8}
      REDIS_URL: ${FIRECRAWL_REDIS_URL:-redis://redis:6379}
      REDIS_RATE_LIMIT_URL: ${FIRECRAWL_REDIS_URL:-redis://redis:6379}
      PLAYWRIGHT_MICROSERVICE_URL: ${FIRECRAWL_PLAYWRIGHT_MICROSERVICE_URL:-http://playwright-service:3000/scrape}
      USE_DB_AUTHENTICATION: ${FIRECRAWL_USE_DB_AUTHENTICATION:-false}
      POSTGRES_USER: ${FIRECRAWL_POSTGRES_USER:-firecrawl}
      POSTGRES_PASSWORD: ${FIRECRAWL_POSTGRES_PASSWORD:-firecrawl}
      POSTGRES_DB: ${FIRECRAWL_POSTGRES_DB:-firecrawl}
      POSTGRES_PORT: 5432
      POSTGRES_HOST: ${FIRECRAWL_POSTGRES_HOST:-nuq-postgres}
      OPENROUTER_KEY: ${OPENROUTER_KEY}
      OPENROUTER_BASE_URL: ${OPENROUTER_BASE_URL}
      MODEL_NAME: ${FIRECRAWL_LLM_MODEL:-gpt-4o}
      BULL_AUTH_KEY: ${FIRECRAWL_BULL_AUTH_KEY:-}
      NUQ_DATABASE_URL: postgres://${FIRECRAWL_POSTGRES_USER:-firecrawl}:${FIRECRAWL_POSTGRES_PASSWORD:-firecrawl}@${FIRECRAWL_POSTGRES_HOST:-nuq-postgres}:5432/${FIRECRAWL_POSTGRES_DB:-firecrawl}
      NUQ_RABBITMQ_URL: amqp://${FIRECRAWL_RABBITMQ_USER:-firecrawl}:${FIRECRAWL_RABBITMQ_PASSWORD:-firecrawl}@rabbitmq:5672
      USE_RABBITMQ: "true"
    depends_on:
      redis:
        condition: service_started
      playwright-service:
        condition: service_started
      nuq-postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    command: ["node", "dist/src/harness.js", "--start-docker"]
    networks:
      - firecrawl-network
      - traefik-net
      - app-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3002/v0/health/liveness', (r) => { process.exit(r.statusCode === 200 ? 0 : 1) }).on('error', () => process.exit(1))\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

volumes:
  firecrawl_pgdata:
  firecrawl_rabbitmq_data:
  searxng-config:

